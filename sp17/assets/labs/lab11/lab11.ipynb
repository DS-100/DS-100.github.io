{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 11: Regularization and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -U sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.linear_model as lm\n",
    "import scipy.io as sio\n",
    "\n",
    "!pip install -U okpy\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab11.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's lab covers:\n",
    "\n",
    "- How to use regularization to avoid overfitting\n",
    "- How to use cross-validation to find the amount of regularization that produces a model with the least error for new data\n",
    "\n",
    "## Dammed Data\n",
    "\n",
    "We've put our data into two files: `train.csv` and `test.csv` which contain\n",
    "the training and test data, respectively. You are not allowed to train\n",
    "on the test data.\n",
    "\n",
    "The y values in the training data correspond to the amount of water that flows out of the dam on a particular day.  There is only 1 feature: the increase in water level for the dam's reservoir on that day, which we'll call x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X = data[['X']].as_matrix()\n",
    "y = data['y'].as_matrix()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = plt.plot(X[:, 0], y, '.')\n",
    "plt.xlabel('Change in water level (X)')\n",
    "plt.ylabel('Water flow out of dam (y)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_and_curve(curve_x, curve_y):\n",
    "    plt.plot(X[:, 0], y, '.')\n",
    "    plt.plot(curve_x, curve_y, '-')\n",
    "    plt.ylim(-20, 60)\n",
    "    plt.xlabel('Change in water level (X)')\n",
    "    plt.ylabel('Water flow out of dam (y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** As a warmup, let's fit a line to this data using `sklearn`.\n",
    "We've imported [`sklearn.linear_model`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) as `lm`, so you can use that instead of\n",
    "typing out the whole module name. Running the cell should show the data\n",
    "with your best fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_clf = ...\n",
    "\n",
    "# Fit your classifier\n",
    "linear_clf.fit(X, y)\n",
    "\n",
    "# Predict a bunch of points to draw best fit line\n",
    "all_x = np.linspace(-55, 55, 200).reshape(-1, 1)\n",
    "line = linear_clf.predict(all_x)\n",
    "\n",
    "plot_data_and_curve(all_x, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** If you had to guess, which has a larger effect on error for this dataset: bias or variance?\n",
    "Explain briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Let's now add some complexity to our model by adding polynomial features.\n",
    "\n",
    "Reference the `sklearn` docs on the `PolynomialFeatures` class. You should use this class to add polynomial features to `X` up to degree 8 using the `fit_transform` method.\n",
    "\n",
    "The final `X_poly` data matrix should have shape `(33, 9)`. Think about and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_poly = ...\n",
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Now, fit a linear regression to the data, using polynomial features.\n",
    "\n",
    "Then, follow the code in Question 1 to make predictions for the values in `all_x`. You'll have to add polynomial features to `all_x` in order to make predictions.\n",
    "\n",
    "Then, running this cell should plot the best fit curve using a degree 8 polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly_clf = ...\n",
    "\n",
    "# Fit your classifier\n",
    "...\n",
    "\n",
    "# Set curve to your model's predictions on all_x\n",
    "curve = ...\n",
    "\n",
    "plot_data_and_curve(all_x, curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Think about and discuss what you notice in the model's predictions.\n",
    "\n",
    "Now, compute the mean squared training error for both the best fit line and polynomial. Again, you'll have to transform the training data for the polynomial regression before you can make predictions.\n",
    "\n",
    "You should get training errors of around 52.8 and 5.23 for line and polynomial models, respectively. Why does the polynomial model get a lower training error than the linear model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse(predicted_y, actual_y):\n",
    "    return np.mean((predicted_y - actual_y) ** 2)\n",
    "\n",
    "line_training_error = ...\n",
    "poly_training_error = ...\n",
    "\n",
    "line_training_error, poly_training_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** It's annoying to have to transform the data every time we want to use polynomial features. We can use a [`Pipeline`](http://scikit-learn.org/stable/modules/pipeline.html#pipeline) to let us do both transformation and regression in one step.\n",
    "\n",
    "Read the docs for [`make_pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) and create a pipeline for polynomial regression called `poly_pipeline`. Then, fit it on `X` and `y` and compute the training error as in Question 5. The training errors should match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "poly_pipeline = ...\n",
    "\n",
    "# Fit the pipeline on X and y\n",
    "...\n",
    "\n",
    "# Compute the training error\n",
    "pipeline_training_error = ...\n",
    "pipeline_training_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! With pipelines, we can combine any number of transformations and treat the whole thing as a single classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** Now, we know that a low training error doesn't necessarily mean your model is good. So, we'll hold out some points from the training data for a *validation set*. We'll use these held-out points to choose the best model.\n",
    "\n",
    "Use the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out one third of the training data for validation. Call the resulting datasets `X_train`, `X_valid`, `y_train`, `y_valid`.\n",
    "\n",
    "`X_train` should have shape `(22, 1)`. `X_valid` should have shape `(11, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "...\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** Now, set `X_train_line_error`, `X_valid_line_error`,\n",
    "`X_train_poly_error`, `X_valid_poly_error` to the training and validation\n",
    "errors for both linear and polynomial regression.\n",
    "\n",
    "You'll have to call `.fit` on your classifiers/pipelines again since we're using\n",
    "`X_train` and `y_train` instead of `X` and `y`.\n",
    "\n",
    "You should see that the validation error for the polynomial fit is significantly\n",
    "higher than the linear fit (152.6 vs 115.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the linear classifier\n",
    "...\n",
    "\n",
    "# Fit the polynomial pipeline\n",
    "...\n",
    "\n",
    "X_train_line_error = ...\n",
    "X_valid_line_error = ...\n",
    "\n",
    "X_train_poly_error = ...\n",
    "X_valid_poly_error = ...\n",
    "\n",
    "X_train_line_error, X_valid_line_error, X_train_poly_error, X_valid_poly_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 9:** Our 8 degree polynomial is overfitting our data.\n",
    "To reduce overfitting, we can use **regularization**.\n",
    "\n",
    "The usual cost function for linear regression is:\n",
    "\n",
    "$$J(\\theta) = (Y - X \\theta)^T (Y - X \\theta)$$\n",
    "\n",
    "Edit the cell below to show the cost function of linear regressions with L2 regularization. Use\n",
    "$\\lambda $ as your regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(\\theta) = (Y - X \\theta)^T (Y - X \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now,** explain why this cost function helps reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:** L2 regularization for linear regression is also known as\n",
    "*Ridge* regression. Create a pipeline called `ridge_pipeline` that again\n",
    "creates polynomial features with degree 8 and then uses the `Ridge` sklearn \n",
    "classifier.\n",
    "\n",
    "The `alpha` argument is the same as our $\\lambda$. Leave it as the default (1.0). You should set `normalize=True` to normalize your data before fitting. Why do we have to do this?\n",
    "\n",
    "Then, fit your pipeline on the data. The cell will then plot the curve of your\n",
    "regularized classifier. You should notice the curve is significantly\n",
    "smoother.\n",
    "\n",
    "Then, fiddle around with the alpha value. What do you notice as you\n",
    "increase alpha? Decrease alpha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_pipeline = ...\n",
    "\n",
    "# Fit your classifier\n",
    "...\n",
    "\n",
    "# Set curve to your model's predictions on all_x\n",
    "ridge_curve = ...\n",
    "\n",
    "plot_data_and_curve(all_x, ridge_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11:** Compute the training and validation error for the `ridge_pipeline`.\n",
    "\n",
    "How do the errors compare to the errors for the unregularized model? Why did each one go up/down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_train_error = ...\n",
    "ridge_valid_error = ...\n",
    "\n",
    "ridge_train_error, ridge_valid_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12:** Now we want to know: how do we choose the best alpha value?\n",
    "\n",
    "This is where we use our validation set. We can try out a bunch of alphas and pick the one that gives us the least error on the validation set. Why can't we use the one that gives us the least error on the training set? The test set?\n",
    "\n",
    "For each alpha in the given `alphas` list, fit a Ridge regression model to the training set and check its accuracy on the validation set.\n",
    "\n",
    "Finally, set `best_alpha` to the best value. You should get a best alpha of 0.01 with a validation error of 15.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "\n",
    "# Your code to find the best alpha\n",
    "...\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13:** Now, set `best_pipeline` to the pipeline with the degree 8 polynomial transform and the ridge regression model with the best value of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_pipeline = ...\n",
    "\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "best_curve = best_pipeline.predict(all_x)\n",
    "\n",
    "plot_data_and_curve(all_x, best_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to find the test error of your simple linear model, your polynomial model, and your regularized polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "X_test = data[['X']].as_matrix()\n",
    "y_test = data['y'].as_matrix()\n",
    "\n",
    "line_test_error = mse(linear_clf.predict(X_test), y_test)\n",
    "poly_test_error = mse(poly_pipeline.predict(X_test), y_test)\n",
    "best_test_error = mse(best_pipeline.predict(X_test), y_test)\n",
    "\n",
    "line_test_error, poly_test_error, best_test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! You've use regularization and cross-validation to fit an accurate polynomial model to the dataset.\n",
    "\n",
    "In the future, you'd probably want to use something like [`RidgeCV`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV) to automatically perform cross-validation, but it's instructive to do it yourself at least once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting your assignment\n",
    "If you made a good-faith effort to complete the lab, change `i_finished_the_lab` to `True` in the cell below.  In any case, run the cells below to submit the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_finished_the_lab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('qcompleted')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, run this code in your terminal to make a\n",
    "[git commit](https://www.atlassian.com/git/tutorials/saving-changes/git-commit)\n",
    "that saves a snapshot of your changes in `git`. The last line of the cell\n",
    "runs [git push](http://stackoverflow.com/questions/2745076/what-are-the-differences-between-git-commit-and-git-push), which will send your work to your personal Github repo.\n",
    "\n",
    "    # Tell git to commit your changes to this notebook\n",
    "    git add -A\n",
    "    \n",
    "    # Tell git to make the commit\n",
    "    git commit -m \"lab11 finished\"\n",
    "    \n",
    "    # Send your updates to your personal private repo\n",
    "    git push origin master"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

