{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9: The Poisson Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install -U okpy\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab09.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's lab has two topics:\n",
    "1. The Poisson process model.  This is a model for events that happen \"randomly\" in time.  It pops up in Homework 5.\n",
    "2. Solving least-squares problems with a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Poisson process\n",
    "Homework 5 uses a Poisson process model in the context of website updates: A website could be updated at any time, and you can't really predict when an update will happen based on previous update times.\n",
    "\n",
    "Here are a few more situations where events could be modeled by a Poisson process:\n",
    "1. Cars are arriving at an intersection when traffic is flowing freely.\n",
    "2. Customers are visiting an online store.\n",
    "3. Rain drops are falling on a field during a storm.\n",
    "4. Radiation particles are being emitted by a radioactive object.\n",
    "\n",
    "We use the term \"random variable\" for *numbers* or *single quantities* that are random, but of course other things can be random, too.  A Poisson process is a random *set* of numbers.  For example:\n",
    "\n",
    "1. The times when cars or customers arrive, or when radiation particles are emitted.\n",
    "2. The places where rain drops fall.\n",
    "\n",
    "It arises any time the set has just two properties:\n",
    "\n",
    "> A. All numbers that are possible have equal chances to appear.\n",
    "\n",
    "> B. Knowing that certain numbers appear in the set doesn't tell you anything about whether other numbers appear in the set.  In other words, numbers appear *independently* in the set.\n",
    "\n",
    "The second assumption is often problematic.  For example, it's violated to some degree in the following situations:\n",
    "\n",
    "1. Cars are arriving at an intersection, but they all arrive around the same time because they were waiting for a light at a previous intersection.\n",
    "2. Customers are visiting an online store, but sometimes a big event (like a new product launch) makes many customers visit at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ooober\n",
    "Suppose you are working in the Public Relations office at the ridesharing company Ooober.  Your company is somewhat prone to scandal.  Normally, one or two scandals are okay, but it is very bad when more than 3 scandals happen in one month, because then the media starts to write \"pile-on\" stories about how scandal-prone Ooober is.\n",
    "\n",
    "You would like to model scandals and estimate how likely it is for more than 3 scandals to happen in a month.\n",
    "\n",
    "Run the next cell to load the `scandals` table.  It corresponds to the following schema:\n",
    "\n",
    "    scandals(primary key (scandal_id), time)\n",
    "\n",
    "The times are given in *fractions of a month* from January 2014 to December 2015.  For simplicity, in this lab, just assume every month has 30 days and every day has 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scandals = pd.read_csv('scandals.csv')\n",
    "scandals.set_index('scandal_id', inplace=True)\n",
    "scandals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a function for viewing timelines of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_points(points, xlim, title):\n",
    "    \"\"\"Displays a timeline with points on it.\n",
    "    \n",
    "    Args:\n",
    "      points (ndarray): A list of floats in the range [xlim[0], xlim[1]],\n",
    "                        each one a point to display in the timeline.\n",
    "      xlim (list-like): A list/tuple/array with 2 elements giving the\n",
    "                        start and end of the timeline.\n",
    "      title (str): The name to display on the plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.set_size_inches(8, 1)\n",
    "    ax.scatter(points, np.repeat(0, len(points)))\n",
    "    ax.axhline(0, color=\"grey\", zorder=-1, lw=.5)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.xaxis.set_visible(True)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_title(\"{} ({:d} total points)\".format(title, len(points)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Display the timeline of scandals at Ooober."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_months = 24\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "What was the average number of scandals per month at Ooober over the last 2 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_scandals_per_month = ...\n",
    "average_scandals_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q3')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to simulate possible future scandal patterns.  To do that, we need a model for the scandals, and we need to learn the parameters of that model from our data.\n",
    "\n",
    "The scandals look somewhat spread out.  Suppose we are willing to assume that they follow a Poisson process.  Remember, that means:\n",
    "\n",
    "> A. Scandals are equally likely to happen at any time.\n",
    "\n",
    "> B. Scandals happen independently.  That means a scandal is no more or less likely to happen tomorrow if one happened today.\n",
    "\n",
    "How would we simulate future scandals under this model?\n",
    "\n",
    "If the average number of scandals per month is $r$, then the average number of scandals per day must be $\\frac{r}{30}$ (remember, we're assuming there are 30 days in each month), and the average number of scandals per hour must be $\\frac{r}{30 \\times 24}$.  Notice that under assumption A, this is true for *all* hours, even 3 AM on a Sunday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "What was the average number of scandals per second at Ooober over the last 2 years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_scandals_per_second = ...\n",
    "average_scandals_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q4')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems okay to neglect the chance that there are 2 scandals in one second!  In that case, whether a scandal happens in a particular second is a Bernoulli($p$) random variable: 1 if there is a scandal and 0 otherwise.\n",
    "\n",
    "#### Question 5\n",
    "In order for the average number of scandals per second to match your answer to the previous question, what should $p$ be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = ...\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q5')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Draw from a Bernoulli($p$) distribution for each second in two years.  Count each 1 you find as a scandal at the start of that second.  Set `q6_simulated_scandals` to a list of those seconds, **converted to months since the start of the first year**.\n",
    "\n",
    "*Hint:* `np.random.random(size=n)` will generate an array of `n` numbers uniformly distributed between 0 and 1.  Therefore, each element of the array `np.random.random(size=n) <= p` has an independent chance `p` to be `True` and chance `1-p` to be `False`.\n",
    "\n",
    "*Hint 2:* You may find the function `np.where` useful.  `np.where(array_of_booleans)[0]` is an array of indices where `array_of_booleans` is `True`.  Note the `[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seconds_in_a_month = 30*24*60*60\n",
    "\n",
    "q6_simulated_scandals = ...\n",
    "\n",
    "display_points(q6_simulated_scandals, [0, num_months], \"Simulated scandals in 2 years\")\n",
    "q6_simulated_scandals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Encapsulate your work in a function called `draw_approximate_poisson_process`, as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_approximate_poisson_process(rate, length, steps_per_unit_length):\n",
    "    \"\"\"Draws from an approximate Poisson process on [0, length] with the given rate.\n",
    "    \n",
    "    This function simulates the number of times a thing happens, if the\n",
    "    thing happens or doesn't happen randomly according to a Bernoulli\n",
    "    distribution at each time step.  The number of time steps simulated\n",
    "    is:\n",
    "    \n",
    "        length * steps_per_unit_length.\n",
    "        \n",
    "    The average number of things that happen is:\n",
    "    \n",
    "        rate * length.\n",
    "    \n",
    "    Args:\n",
    "      rate (float): The average number of times the thing happens per\n",
    "                    unit length.\n",
    "      length (float): The length of time to be simulated.\n",
    "      steps_per_unit_length (float): The number of Bernoulli draws per unit length.\n",
    "                                     length*steps_per_unit_length must be an integer.\n",
    "                                     (That guarantee isn't strictly necessary but\n",
    "                                     simplifies the implementation of this function.)\n",
    "     \n",
    "    Returns:\n",
    "      ndarray: A NumPy array containing the times when the thing happened.\n",
    "               (If a event happened during a time step, this function can\n",
    "               choose any time for the event between the time step and the\n",
    "               next one.)\n",
    "    \"\"\"\n",
    "    # We suggest computing the number of steps like this:\n",
    "    num_steps = int(np.round(length * steps_per_unit_length))\n",
    "    p = ...\n",
    "    ...\n",
    "\n",
    "draw_approximate_poisson_process(average_scandals_per_month, num_months, seconds_in_a_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "You might notice that your function takes some time to run.  To speed things up, let's switch the granularity of our simulations from seconds to *minutes*.  This will give us a slightly worse approximation to the Poisson process, but it still seems plausible that 2 scandals never happen in the same minute.\n",
    "\n",
    "**Now,** by calling your function 100-1000 times, estimate the chance that (over the next 24 months, assuming the rate of scandals remains the same) Ooober experiences 3 or more scandals in *at least* one month.  This is called a Monte Carlo simulation.\n",
    "\n",
    "**Note:** This may take up to a minute.  Try using fewer simulations when you first run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "num_simulations = 1000\n",
    "minutes_in_a_month = 30*24*60\n",
    "\n",
    "...\n",
    "\n",
    "three_or_more_scandals_chance = ...\n",
    "three_or_more_scandals_chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q8')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Poisson distribution\n",
    "Often, we don't care about exactly *when* events happen, only *how many* of them happen in a certain interval.  A Poisson($\\lambda$) random variable (not a process) is the number of events that happen in some Poisson process that has `rate*length` equal to $\\lambda$.\n",
    "\n",
    "Since `draw_approximate_poisson_process` has approximately a Poisson process distribution, an expression like:\n",
    "\n",
    "    len(draw_approximate_poisson_process(2, 3, 1000))\n",
    "\n",
    "...has *approximately* a Poisson($2 \\times 3$) distribution.\n",
    "\n",
    "However, we can characterize the distribution of your approximation exactly.  Your approximation draws from many Bernoulli random variables.  The number of events that happen is a *sum* of those Bernoulli random variables.  Therefore, the number of events follows exactly a *Binomial* distribution!\n",
    "\n",
    "Recall that the Binomial distribution has two parameters: $n$, the number of Bernoulli random variables that are summed, and $p$, the probability that any one of them is 1.  It's written Binomial($n$, $p$).  The expected value is $n \\times p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "What is the exact distribution of the results of this call?\n",
    "\n",
    "    len(draw_approximate_poisson_process(r, l, d))\n",
    "    \n",
    "Give the Binomial parameters $n$ and $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example values for r, l, and d so that this cell can run:\n",
    "r = .2\n",
    "l = 10\n",
    "d = 3\n",
    "\n",
    "n = ...\n",
    "p = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q9')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `d` increases, the time steps get narrower, and the Binomial(`l*d`, `r/d`) distribution becomes the same as the Poisson(`l*r`) distribution.  In homework 5, you'll see another way to simulate data from the Poisson process that takes advantage of this fact.  The cell below uses your `draw_approximate_poisson_process` function to show by simulation that:\n",
    "\n",
    "$$\\text{Binomial}(ld, \\frac{r}{d}) \\to \\text{Poisson}(lr) \\text{ as }d \\to \\infty.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_poisson_approximation(r, l, num_step_sizes, num_simulations):\n",
    "    import math\n",
    "    max_output = int(r*l + 6*(r*l)**0.5)\n",
    "    true_poisson_pmf = [math.exp(-r*l) * (r*l)**k / math.factorial(k) for k in range(max_output)]\n",
    "    min_steps_per_length = r*2\n",
    "    steps_per_length = min_steps_per_length * 2**np.arange(num_step_sizes)\n",
    "    def approximate_pmf(s):\n",
    "        draws = [len(draw_approximate_poisson_process(r, l, s)) for _ in range(num_simulations)]\n",
    "        return np.bincount(draws, minlength=max_output) / num_simulations\n",
    "    \n",
    "    approximate_pmfs = [approximate_pmf(s) for s in steps_per_length]\n",
    "    approximate_pmf_names = [\"Approximation to Poisson PMF (Binomial({:d}, {:.4f}))\".format(int(np.round(l*s)), r/s)\n",
    "                             for s in steps_per_length]\n",
    "    from matplotlib import cm\n",
    "    colors = [cm.jet(x) for x in np.linspace(0, 1, len(steps_per_length)+1)]\n",
    "    \n",
    "    for pmf, name, color in zip(approximate_pmfs + [true_poisson_pmf], approximate_pmf_names + [\"True Poisson({:.4f}) PMF\".format(r*l)], colors):\n",
    "        plt.scatter(range(len(pmf)), pmf, c=color, label=name, s=40)\n",
    "        plt.plot(range(len(pmf)), pmf, c=color, linestyle='dashed')\n",
    "        plt.legend()\n",
    "        plt.title(\"Approximations to the Poisson distribution\\n(dashed lines are for contrast purposes only)\")\n",
    "        plt.xlabel(\"Count\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "\n",
    "plot_poisson_approximation(.2, 10, 5, 40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares\n",
    "Now let's turn to a new topic entirely: least-squares linear regression.  To save time, we won't look at a real-world or even a fictitious problem.  Our goal is to get some concrete experience solving least-squares problems with a computer.\n",
    "\n",
    "In last week's lab, you saw that you could maximize a function on a computer by plotting its values over a range of inputs.  A computer can automate that process and improve on it in various ways.  This is called *numerical optimization*.  The main numerical optimization tool we'll use is the function `sc.optimize.minimize` from the SciPy package.  There are many, many more.\n",
    "\n",
    "The problem in least-squares linear regression is:\n",
    "\n",
    "> For $n$ entities $i$ = 0 through $n-1$, find a prediction function that predicts their outcomes $y_0$, $y_1$, ..., $y_{n-1}$ well.  To help us make predictions, we have available for each entity a vector of $p$ numerical features, $x_i \\in \\mathcal{R}^p$.  We limit ourselves to linear prediction functions: functions that look like $f(x) = \\theta \\boldsymbol{\\cdot} x$ for some parameter vector $\\theta$.  We would like to find the $f$ that produces the least squared prediction error, averaged over the $n$ entities.\n",
    "\n",
    "In more succinct mathematical terms (in case you prefer such language), the problem is to find:\n",
    "\n",
    "$$\\text{least squares prediction function} = \\arg\\min_{f \\in \\text{linear functions}} L(f; (x_i)_{i=0}^{n-1}, (y_i)_{i=0}^{n-1})$$\n",
    "\n",
    "where the loss function is:\n",
    "\n",
    "$$L(f; (x_i)_{i=0}^{n-1}, (y_i)_{i=0}^{n-1}) = \\frac{1}{n} \\sum_{i=0}^{n-1} (f(x_i) - y_i)^2.$$\n",
    "\n",
    "It helps to make the dependence of $f$ on parameters $\\theta$ more explicit.  So we define $f_\\theta$ as the linear function $f_\\theta(x) = \\theta \\boldsymbol{\\cdot} x$.  Then the problem becomes:\n",
    "\n",
    "$$\\theta^{\\text{least squares}} = \\arg\\min_{\\theta \\in \\mathcal{R}^p} \\frac{1}{n} \\sum_{i=0}^{n-1} (f_\\theta(x) - y_i)^2.$$\n",
    "\n",
    "To help us visualize the data and our prediction function, we will take $p = 2$ and $n = 100$, but nothing would change except computation time and accuracy if we increased $p$ or $n$.\n",
    "\n",
    "Running the three cells below will create an interactive visualization of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"least_squares_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_linear_prediction(data, theta=None, orient_x = 45, orient_y = 45):\n",
    "    import math\n",
    "    from matplotlib import patches, cm\n",
    "    from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    plot_predictions = theta is not None\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    if plot_predictions:\n",
    "        actual_xs = data[['x0', 'x1']].as_matrix()\n",
    "        predicted_ys = np.dot(actual_xs, theta)\n",
    "        \n",
    "        def plot_points_and_residuals(point_indicators, ax, occluded):\n",
    "            to_plot = data.loc[point_indicators]\n",
    "            ax.hold(True)\n",
    "            ax.scatter(to_plot[\"x0\"], to_plot[\"x1\"], to_plot[\"y\"], \n",
    "                       c='black',\n",
    "                       zorder=-1 if occluded else 100)\n",
    "            \n",
    "            for i in np.where(point_indicators)[0]:\n",
    "                x0, x1 = actual_xs[i,:]\n",
    "                y = data['y'][i]\n",
    "                predicted_y = predicted_ys[i]\n",
    "                ax.hold(True)\n",
    "                ax.plot([x0, x0], [x1, x1], [y, predicted_y],\n",
    "                        c='red',\n",
    "                        linestyle='dotted' if occluded else 'solid',\n",
    "                        lw=1 if occluded else 2)\n",
    "        \n",
    "        # Figuring out which points are in front of the surface:\n",
    "        orient_x_rad = orient_x*math.pi/180\n",
    "        orient_y_rad = orient_y*math.pi/180\n",
    "        viewpoint_coords = [\n",
    "            np.sin(orient_x_rad)*np.cos(orient_y_rad),\n",
    "            np.cos(orient_x_rad)*np.cos(orient_y_rad),\n",
    "            np.sin(orient_y_rad)]\n",
    "        prediction_surface_normal = [theta[0], theta[1], -1]\n",
    "        viewpoint_above_surface = np.dot(viewpoint_coords, prediction_surface_normal) >= 0\n",
    "        point_in_front_of_surface = ((predicted_ys - data['y']) >= 0) == viewpoint_above_surface\n",
    "        \n",
    "        plot_points_and_residuals(~point_in_front_of_surface, ax, True)\n",
    "        \n",
    "        # Plotting the surface:\n",
    "        xs = np.array(np.meshgrid(\n",
    "            np.linspace(min(data['x0']), max(data['x0']), 5),\n",
    "            np.linspace(min(data['x1']), max(data['x1']), 5)))\n",
    "        ys = np.tensordot(theta, xs, axes=1)\n",
    "        ax.hold(True)\n",
    "        prediction_plane = ax.plot_surface(xs[0], xs[1], ys,\n",
    "                                           cmap=cm.coolwarm)\n",
    "        \n",
    "        plot_points_and_residuals(point_in_front_of_surface, ax, False)\n",
    "        \n",
    "        squared_loss = np.mean((predicted_ys - data['y'])**2)\n",
    "        plt.title(\"data, predictions, and residuals\\n(current average squared prediction error = {:.2f})\".format(squared_loss))\n",
    "    else:\n",
    "        prediction_plane = ax.scatter(data[\"x0\"], data[\"x1\"], data[\"y\"], \n",
    "                                      cmap=cm.coolwarm)\n",
    "        plt.title(\"raw data\")\n",
    "        \n",
    "    ax.zaxis.set_major_locator(LinearLocator(5))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    ax.view_init(orient_y, orient_x)\n",
    "    ax.set_xlabel(\"x0 (feature 0)\")\n",
    "    ax.set_ylabel(\"x1 (feature 1)\")\n",
    "    ax.set_zlabel(\"y (the thing we're predicting)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_predictor(theta0, theta1, orient_x, orient_y, plot_predictions):\n",
    "    theta = [theta0, theta1]\n",
    "    display_linear_prediction(data, theta if plot_predictions else None, orient_x, orient_y)\n",
    "\n",
    "theta0 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "theta1 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "orient_x = widgets.FloatSlider(min=0, max=90, step=1, value=45, description=\"x rotation\")\n",
    "orient_y = widgets.FloatSlider(min=0, max=90, step=1, value=45, description=\"y rotation\")\n",
    "plot_predictions = widgets.Checkbox(value=True, description=\"Plot predictions on top of data?\")\n",
    "\n",
    "interact(plot_predictor, theta0=theta0, theta1=theta1, orient_x=orient_x, orient_y=orient_y, plot_predictions=plot_predictions);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10\n",
    "Play around with the graph above to find a good predictor $\\theta = (\\theta_0, \\theta_1)$.  It should have squared prediction error around 1 or less.  (If the graph draws slowly on your computer, just move on to the next question.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11\n",
    "Write the objective function `least_squares_loss` as described in its docstring.\n",
    "\n",
    "*Big hint:* The function `np.dot` and the DataFrame method `as_matrix` will be useful.  Despite the name, `np.dot` can perform matrix-vector multiplication.  And `as_matrix` converts a DataFrame to a 2d NumPy array.  For example,\n",
    "\n",
    "    np.dot(data[['x0', 'x1']].as_matrix(), [-5, 3])\n",
    "\n",
    "...is an array with one element for each entity.  For each entity, the value is -5 times the `x0` feature for the entity plus 3 times the `x1` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_loss(theta):\n",
    "    \"\"\"The average squared prediction error when the function\n",
    "        f: x => theta . x\n",
    "    is used to predict y for our dataset.\n",
    "    \n",
    "    The dataset is the DataFrame named data.\n",
    "    \n",
    "    Args:\n",
    "      theta (ndarray): A vector of p numbers.  The prediction function\n",
    "                       is f: x => theta . x, the dot product with theta.\n",
    "    \n",
    "    Returns:\n",
    "      float: The average (over the DataFrame named data) of the\n",
    "             squared prediction error.\n",
    "    \"\"\"\n",
    "    # Our solution defined an array called predictions; you\n",
    "    # don't have to.\n",
    "    predictions = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q11')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12\n",
    "Import the `scipy.optimize` module as `scopt` and call `scopt.minimize` on `least_squares_loss`.  Name the result `optimization_result` and study it.\n",
    "\n",
    "*Hint:* You'll need to provide one additional argument: an initial guess.  It's best to start with the origin (`np.zeros((2))`) or a random location near the origin (`np.random.normal(0, 1, size=2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as scopt\n",
    "optimization_result = ...\n",
    "optimization_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q12')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13\n",
    "Interpret the output of `scopt.minimize`.  Which field do you think is $\\theta^{\\text{least squares}}$?  Which tells you the average squared prediction error for that value of $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14\n",
    "The three cells below create two interactive graphs; we've added a heat map displaying your `least_squares_loss` function.  Plug in the value you found for $\\theta^{\\text{least squares}}$ (or as close as you can get) in both.  Rotate the data graph to see how well the prediction function fits.\n",
    "\n",
    "*Note:* Unfortunately, the heat map is a little slow to display and update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowsize = 5\n",
    "maxloss = least_squares_loss([windowsize, -windowsize])\n",
    "losses_flattened = pd.DataFrame.from_records(\n",
    "    [(t0, t1)\n",
    "     for t0 in np.linspace(-windowsize, windowsize, 30)\n",
    "     for t1 in np.linspace(-windowsize, windowsize, 30)\n",
    "     for _ in range(int(math.ceil((maxloss-least_squares_loss([t0, t1]))/(maxloss/10))))],\n",
    "    columns=[\"theta0\", \"theta1\"])\n",
    "\n",
    "def display_loss_heatmap(theta):\n",
    "    sns.kdeplot(losses_flattened['theta0'], losses_flattened['theta1'], shade=True, n_levels=100, color='red')\n",
    "    plt.scatter(theta[0], theta[1], color='orange', s=100, label=\"proposed theta\")\n",
    "    plt.xlim([-windowsize, windowsize])\n",
    "    plt.ylim([-windowsize, windowsize])\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel(\"theta0\")\n",
    "    plt.ylabel(\"theta1\")\n",
    "    plt.title(\"average squared prediction error by theta\\n(darker is lower)\")\n",
    "    plt.legend()\n",
    "\n",
    "def plot_loss(theta0, theta1):\n",
    "    theta = [theta0, theta1]\n",
    "    display_loss_heatmap(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta0 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "theta1 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "orient_x = widgets.FloatSlider(min=0, max=90, step=1, value=45, description=\"x rotation\")\n",
    "orient_y = widgets.FloatSlider(min=0, max=90, step=1, value=45, description=\"y rotation\")\n",
    "plot_predictions = widgets.Checkbox(value=True, description=\"Plot predictions on top of data?\")\n",
    "\n",
    "interact(plot_predictor, theta0=theta0, theta1=theta1, orient_x=orient_x, orient_y=orient_y, plot_predictions=plot_predictions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta0 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "theta1 = widgets.FloatSlider(min=-3, max=3, step=.1, value=0)\n",
    "\n",
    "interact(plot_loss, theta0=theta0, theta1=theta1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting your assignment\n",
    "If you made a good-faith effort to complete the lab, change `i_finished_the_lab` to `True` in the cell below.  In any case, run the cells below to submit the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_finished_the_lab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('qcompleted')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run this code in your terminal to make a\n",
    "[git commit](https://www.atlassian.com/git/tutorials/saving-changes/git-commit)\n",
    "that saves a snapshot of your changes in `git`. The last line of the cell\n",
    "runs [git push](http://stackoverflow.com/questions/2745076/what-are-the-differences-between-git-commit-and-git-push), which will send your work to your personal Github repo.\n",
    "\n",
    "    # Tell git to commit your changes to this notebook\n",
    "    git add sp17/lab/lab09/lab09.ipynb\n",
    "    \n",
    "    # Tell git to make the commit\n",
    "    git commit -m \"lab09 finished\"\n",
    "    \n",
    "    # Send your updates to your personal private repo\n",
    "    git push origin master"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

